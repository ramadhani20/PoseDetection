{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 10:34:53.817425: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-04 10:34:54.538244: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-04 10:34:54.538290: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-04 10:34:56.406489: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-04 10:34:56.406587: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-04 10:34:56.406597: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version tensorflow :  2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('version tensorflow : ',tf.__version__)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import save_model\n",
    "import glob\n",
    "import os \n",
    "import numpy as np\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data sheet\n",
    "base_dir = os.path.join('DATASET/')\n",
    "downdog_dir = os.path.join(base_dir,'downdog/')\n",
    "goddes_dir = os.path.join(base_dir,'goddess/')\n",
    "plank_dir = os.path.join(base_dir,'plank/')\n",
    "tree_dir = os.path.join(base_dir,'tree/')\n",
    "warrior2_dir = os.path.join(base_dir,'warrior2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file downdog :  97\n",
      "file goddess :  80\n",
      "file plank :  115\n",
      "file tree :  69\n",
      "file warrior :  109\n"
     ]
    }
   ],
   "source": [
    "total_downdog = len(os.listdir(downdog_dir))\n",
    "total_goddes = len(os.listdir(goddes_dir))\n",
    "total_plank = len(os.listdir(plank_dir))\n",
    "total_tree = len(os.listdir(tree_dir))\n",
    "total_warrior2 = len(os.listdir(warrior2_dir))\n",
    "\n",
    "print('file downdog : ',total_downdog)\n",
    "print('file goddess : ',total_goddes)\n",
    "print('file plank : ',total_plank)\n",
    "print('file tree : ',total_tree)\n",
    "print('file warrior : ',total_warrior2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode = 'nearest',\n",
    "    validation_split = 0.2 \n",
    ")\n",
    " \n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode = 'nearest',\n",
    "    validation_split = 0.2                                  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 378 images belonging to 5 classes.\n",
      "Found 92 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size = (150,150),\n",
    "    batch_size = 16,\n",
    "    shuffle = True,\n",
    "    color_mode = \"rgb\",\n",
    "    class_mode = \"categorical\",\n",
    "    subset = \"training\"\n",
    "    \n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size = (150,150),\n",
    "    batch_size = 16,\n",
    "    shuffle = True,\n",
    "    color_mode = \"rgb\",\n",
    "    class_mode = \"categorical\",\n",
    "    subset = \"validation\"\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 10:36:09.172818: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 10:36:09.173526: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-04 10:36:09.173726: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-04 10:36:09.173865: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-04 10:36:09.173993: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-04 10:36:09.174115: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-04 10:36:09.174243: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-04 10:36:09.174366: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-04 10:36:09.174493: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-04 10:36:09.174517: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-04 10:36:09.176334: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 82944)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 82944)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               10616960  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,636,997\n",
      "Trainable params: 10,636,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#membuat model class adalah untuk mengukur \n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), strides = (1,1),  activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2), padding = 'valid'), \n",
    "    tf.keras.layers.Conv2D(64, (3,3), strides = (1,1), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2), padding = 'valid'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax',kernel_regularizer=tf.keras.regularizers.l2(0.001))\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adam(learning_rate=0.001, name='Adam')\n",
    "model_vis = model.compile(\n",
    "    optimizer = 'Adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 82944)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 82944)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               10616960  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,636,997\n",
      "Trainable params: 10,636,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def scheduler(epoch, lr):\n",
    "  if epoch < 5:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='logs', histogram_freq=0, write_graph=True, write_images=False,\n",
    "    update_freq='epoch', embeddings_freq=0,\n",
    "    embeddings_metadata=None\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0.97\n",
    "\n",
    "class func_callback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('accuracy') >= accuracy):\n",
    "               print('tingkat akurasi : ',accuracy),\n",
    "               self.model.stop_training = True\n",
    "\n",
    "callback = func_callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/20\n",
      "23/23 - 17s - loss: 0.8025 - accuracy: 0.6961 - val_loss: 1.0121 - val_accuracy: 0.6750 - lr: 0.0010 - 17s/epoch - 759ms/step\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/20\n",
      "23/23 - 16s - loss: 0.7312 - accuracy: 0.7293 - val_loss: 1.0175 - val_accuracy: 0.6625 - lr: 0.0010 - 16s/epoch - 685ms/step\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/20\n",
      "23/23 - 16s - loss: 0.6577 - accuracy: 0.7845 - val_loss: 0.8423 - val_accuracy: 0.7375 - lr: 0.0010 - 16s/epoch - 700ms/step\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/20\n",
      "23/23 - 15s - loss: 0.6549 - accuracy: 0.7680 - val_loss: 0.9523 - val_accuracy: 0.6750 - lr: 0.0010 - 15s/epoch - 671ms/step\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/20\n",
      "23/23 - 19s - loss: 0.6070 - accuracy: 0.7735 - val_loss: 1.0643 - val_accuracy: 0.6625 - lr: 0.0010 - 19s/epoch - 828ms/step\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0009048374486155808.\n",
      "Epoch 6/20\n",
      "23/23 - 16s - loss: 0.5949 - accuracy: 0.7873 - val_loss: 1.0040 - val_accuracy: 0.6625 - lr: 9.0484e-04 - 16s/epoch - 686ms/step\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0008187307976186275.\n",
      "Epoch 7/20\n",
      "23/23 - 15s - loss: 0.5600 - accuracy: 0.8066 - val_loss: 1.0314 - val_accuracy: 0.6875 - lr: 8.1873e-04 - 15s/epoch - 644ms/step\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0007408182718791068.\n",
      "Epoch 8/20\n",
      "23/23 - 15s - loss: 0.5156 - accuracy: 0.8149 - val_loss: 0.7653 - val_accuracy: 0.7000 - lr: 7.4082e-04 - 15s/epoch - 640ms/step\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0006703201215714216.\n",
      "Epoch 9/20\n",
      "23/23 - 15s - loss: 0.5123 - accuracy: 0.8149 - val_loss: 1.0854 - val_accuracy: 0.6750 - lr: 6.7032e-04 - 15s/epoch - 672ms/step\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0006065307534299791.\n",
      "Epoch 10/20\n",
      "23/23 - 15s - loss: 0.4821 - accuracy: 0.8398 - val_loss: 1.0120 - val_accuracy: 0.7000 - lr: 6.0653e-04 - 15s/epoch - 640ms/step\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0005488117458298802.\n",
      "Epoch 11/20\n",
      "23/23 - 15s - loss: 0.4287 - accuracy: 0.8591 - val_loss: 0.9003 - val_accuracy: 0.6625 - lr: 5.4881e-04 - 15s/epoch - 646ms/step\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0004965853877365589.\n",
      "Epoch 12/20\n",
      "23/23 - 15s - loss: 0.4486 - accuracy: 0.8564 - val_loss: 1.0082 - val_accuracy: 0.7375 - lr: 4.9659e-04 - 15s/epoch - 636ms/step\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0004493290325626731.\n",
      "Epoch 13/20\n",
      "23/23 - 15s - loss: 0.4222 - accuracy: 0.8757 - val_loss: 0.8695 - val_accuracy: 0.6875 - lr: 4.4933e-04 - 15s/epoch - 648ms/step\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0004065697139594704.\n",
      "Epoch 14/20\n",
      "23/23 - 15s - loss: 0.3842 - accuracy: 0.8646 - val_loss: 1.0027 - val_accuracy: 0.7125 - lr: 4.0657e-04 - 15s/epoch - 640ms/step\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.000367879489203915.\n",
      "Epoch 15/20\n",
      "23/23 - 16s - loss: 0.3793 - accuracy: 0.8641 - val_loss: 0.7618 - val_accuracy: 0.7375 - lr: 3.6788e-04 - 16s/epoch - 711ms/step\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0003328711318317801.\n",
      "Epoch 16/20\n",
      "23/23 - 22s - loss: 0.3259 - accuracy: 0.9033 - val_loss: 0.8879 - val_accuracy: 0.7125 - lr: 3.3287e-04 - 22s/epoch - 962ms/step\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.000301194260828197.\n",
      "Epoch 17/20\n",
      "23/23 - 17s - loss: 0.3369 - accuracy: 0.9061 - val_loss: 0.8126 - val_accuracy: 0.7625 - lr: 3.0119e-04 - 17s/epoch - 729ms/step\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0002725318481680006.\n",
      "Epoch 18/20\n",
      "23/23 - 16s - loss: 0.3118 - accuracy: 0.9144 - val_loss: 0.9275 - val_accuracy: 0.7375 - lr: 2.7253e-04 - 16s/epoch - 678ms/step\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0002465970173943788.\n",
      "Epoch 19/20\n",
      "23/23 - 16s - loss: 0.3102 - accuracy: 0.9171 - val_loss: 0.7731 - val_accuracy: 0.7250 - lr: 2.4660e-04 - 16s/epoch - 680ms/step\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00022313020599540323.\n",
      "Epoch 20/20\n",
      "23/23 - 17s - loss: 0.2693 - accuracy: 0.9392 - val_loss: 0.8849 - val_accuracy: 0.7375 - lr: 2.2313e-04 - 17s/epoch - 753ms/step\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "history = model.fit(\n",
    "                  train_generator,\n",
    "                  steps_per_epoch=378//batch_size,\n",
    "                  epochs=20,\n",
    "                  validation_data=validation_generator,\n",
    "                  validation_steps=92//batch_size,\n",
    "                  verbose=2,\n",
    "                  callbacks=[lr_schedule, callback]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpimg\u001b[39;00m\n\u001b[1;32m     10\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m acc \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m val_acc \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m loss \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "#Mengambil Nilai Accuracy\n",
    "# visualisasi hasil data training (Plot accuracy & loss model)\n",
    "\n",
    "import numpy as np\n",
    "import keras.utils as image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    " \n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(20)\n",
    "\n",
    "plt.figure(figsize=(7, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model At model/model.h5...\n"
     ]
    }
   ],
   "source": [
    "MODEL_BASE_PATH = \"model\"\n",
    "SAVE_MODEL_NAME = \"model.h5\"\n",
    "save_model_path = os.path.join(MODEL_BASE_PATH,SAVE_MODEL_NAME)\n",
    "if os.path.exists(os.path.join(MODEL_BASE_PATH)) == False:\n",
    "    os.makedirs(os.path.join(MODEL_BASE_PATH))\n",
    "    \n",
    "print('Saving Model At {}...'.format(save_model_path))\n",
    "model.save(save_model_path,include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'fileinput' has no attribute 'upload'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfileinput\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m uploaded \u001b[39m=\u001b[39m fileinput\u001b[39m.\u001b[39;49mupload()\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m fn \u001b[39min\u001b[39;00m uploaded\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m      6\u001b[0m  \n\u001b[1;32m      7\u001b[0m   \u001b[39m# predicting images\u001b[39;00m\n\u001b[1;32m      8\u001b[0m   path \u001b[39m=\u001b[39m fn\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'fileinput' has no attribute 'upload'"
     ]
    }
   ],
   "source": [
    "import fileinput\n",
    "\n",
    "uploaded = fileinput.upload()\n",
    " \n",
    "for fn in uploaded.keys():\n",
    " \n",
    "  # predicting images\n",
    "  path = fn\n",
    "  img = image.load_img(path, target_size=(150,150))\n",
    " \n",
    "  imgplot = plt.imshow(img)\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  images = np.vstack([x])\n",
    " \n",
    "  classes = model.predict(images, batch_size=16)  \n",
    "\n",
    "  print(fn)\n",
    "  if classes[0, 0] == 1:\n",
    "    print('downdog')\n",
    "  elif classes[0, 1] == 1:\n",
    "    print('goddes')\n",
    "  elif classes[0, 2] == 1:\n",
    "    print('plank')\n",
    "  elif classes[0, 3] == 1:\n",
    "    print('tree')\n",
    "  elif classes[0, 4] == 1:\n",
    "    print('warrior2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gui = Tk(className='Python Examples - Window Color')\n",
    "\n",
    "gui.geometry(\"500x500\")\n",
    "\n",
    "gui['bg']='dimgray'\n",
    "\n",
    "BtnStart = Button(text =\"Start\", fg='black')\n",
    "BtnStart.place(x=50, y = 100)\n",
    "\n",
    "    \n",
    "BtnStart = Button(text =\"Stop\", command=vidioStop)\n",
    "BtnStart.place(x=350, y = 101)\n",
    "\n",
    "BtnStart = Button(text =\"Stop\",bg='red')\n",
    "BtnStart.place(x=200, y = 200)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gui.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
